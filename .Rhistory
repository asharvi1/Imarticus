data = read.csv('2008.csv')
getwd()
setwd("/Users/ravikiran/dektop/R assignment/")
setwd("/Users/ravikiran/dektop/R assignment/")
q()
q()
swirl()
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_list <- sapply(flags, class)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_color <- flags[ , 11:17]
flag_colors <- flags[ , 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[ ,19:23]
lapply(flag_shapes, range)
sapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply()
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
table(flags$population)
tapply(flags$population, flags$landmass, summary)
library(datasets)
data("iris")
?iris
tapply(iris$Sepal.Length, iris$Species, summary)
tapply(iris$Sepal.Length, iris$Species, round(mean, 2))
tapply(iris$Sepal.Length, iris$Species, mean)
head(iris)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
?apply
apply(iris[, 1:4], mean)
library(mtcars)
library(datasets)
data("mtcars")
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
tapply(mtcars$mpg, mtcars$cyl, mean)
dim(mtcars)
colnames(mtcars)
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
sample <- tapply(mtcars$hp, mtcars$cyl, mean)
sample
sample(1)
sample(2)
sample
class(sample)
sample[1]
sample[3] - sample[1]
debug(ls)
ls
ls
?ls
swirl()
library(swirl)
swirl()
library(iris)
library(datasets)
data("iris")
?lapply
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors,mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flag$animate)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
library(datasets)
data(iris)
head(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
apply(iris, 1, mean)
colMeans(iris)
apply(iris[, 1:4], 1, mean)
rowMeans(iris[, 1:4])
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
sapply(mtcars, cyl, mean)
head(mtcars)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
apply(mtcars, 2, mean)
with(mtcars, tapply(mpg, cyl, mean))
mean(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
209.21429 - 82.63636
ls
debug(ls)
ls
x <- c(rnorm(10), runif(10))
install.packages('RMySQL')
install.packages("arules")
library("arules", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
dataset = longley
linear_model = lm(formula = Employed ~ GNP, data = dataset)
# Visualising the residual values in the graph to identify the outliers
qqnorm(resid(linear_model))
plot(dataset$GNP, dataset$Employed)
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed')
abline(lm(Employed ~ GNP))
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red')
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red', pch = 21)
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red', pch = 16)
abline(lm(Employed ~ GNP, data = dataset))
View(dataset)
dataset = dataset[, c(2,7)]
View(dataset)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 1) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 2) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 3) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 4) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point() +
geom_smooth(method = lm)
load("/Users/ravikiran/Desktop/R/Air Quality UCI/airquality.RData")
a = c(2,1,2,3,5,6,7,8,2)
sum(a[a == 2])
dataset = mtcars
# Creating a regression model
regressor = lm(mpg~cyl+wt+am+gear+carb, data = dataset)
summary(regressor)$coefficients
summary(regressor)$estimate
summary(regressor)$Estimate
summary(regressor)coefficients
summary(regressor)$coefficients
library("QuantPsyc", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
lm.beta(regressor)
summary(regressor)$coefficients
install.packages("sirt")
setwd("~/Desktop/Imarticus/Academics/class practice/R")
lm()
lm
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
svm
library("mlbench", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
data("BreastCancer")
dataset = BreastCancer
# Removing the NA values
dataset = na.omit(dataset)
dataset$Id = NULL
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.7)
train_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Fitting the Decision tree model to the training set
classifier = rpart(Class ~ ., data = train_set)
summary(classifier)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.7)
train_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Fitting the Decision tree model to the training set
classifier = rpart(Class ~ ., data = train_set)
summary(classifier)
str(dataset)
summary(classifier)
# Predicting the class of the test data
test_pred_class = predict(classifier, newdata = test_set, type = 'class')
# Predicting the probabilities of the test data
test_pred_prob = predict(classifier, newdata = test_set, type = 'prob')
test_pred_prob
classifier
classifier
plot(classifier)
plot(classifier)
text(classifier)
plot(classifier)
text(classifier)
dev.new()
plot(classifier)
dev.new()
plot(classifier)
text(classifier)
dev.new() # Clearly shows the plot without cutting anything
plot(classifier)
text(classifier)
dev.new() # Clearly shows the plot without cutting anything
plot(classifier)
text(classifier)
dev.new() # Clearly shows the plot without cutting anything
plot(classifier)
text(classifier)
dev.new() # Clearly shows the plot without cutting anything
plot(classifier)
text(classifier)
dev.new() # Clearly shows the plot without cutting anything
plot(classifier)
text(classifier)
install.packages("party")
dev.new(); plot(classifier); text(classifier)
install.packages("party")
library("party", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Creating a model using conditional inference trees
train_set_ct = ctree(Class ~ ., data = train_set)
test_pred_ct = predict(train_set_ct, test_set)
test_pred_ct_prob = 1 - unlist(treeresponse(train_set_ct, test_set), use.names =  FALSE)[seq(1, nrow(test_set) * 2, 2)]
plot(train_set_ct)
plot(train_set_ct)
test_pred_ct_prob
test_pred_ct_prob = 1 - unlist(treeresponse(train_set_ct, test_set), use.names =  TRUE)[seq(1, nrow(test_set) * 2, 2)]
test_pred_ct_prob
test_pred_ct_prob = 1 - unlist(treeresponse(train_set_ct, test_set), use.names =  FALSE)[seq(1, nrow(test_set) * 2, 2)]
View(train_set)
nrow(test_set)
View(test_set)
library("ROCR", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Plotting the ROC curve with the help of ROCR package
test_pred_ROC_prob = prediction(test_pred_prob[, 2], test_set$Class)
library("pROC", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
test_pred_ROC_perf = performance(test_pred_ROC_prob, 'tpr', 'fpr')
plot(test_pred_ROC_perf, col = 2, main = 'ROC Curve')
cm_test = table(test_pred_class, test_set$Class)
cm_test
rm(cm_test)
# Calcualting the auc
auc = auc(test_set$Class, test_pred_class)
# Calcualting the auc
auc = auc(as.numeric(test_set$Class), test_pred_class)
# Calcualting the auc
auc = auc(as.numeric(test_set$Class), as.numeric(test_pred_class))
