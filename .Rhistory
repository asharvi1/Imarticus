data = read.csv('2008.csv')
getwd()
setwd("/Users/ravikiran/dektop/R assignment/")
setwd("/Users/ravikiran/dektop/R assignment/")
q()
q()
swirl()
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_list <- sapply(flags, class)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_color <- flags[ , 11:17]
flag_colors <- flags[ , 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[ ,19:23]
lapply(flag_shapes, range)
sapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply()
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
table(flags$population)
tapply(flags$population, flags$landmass, summary)
library(datasets)
data("iris")
?iris
tapply(iris$Sepal.Length, iris$Species, summary)
tapply(iris$Sepal.Length, iris$Species, round(mean, 2))
tapply(iris$Sepal.Length, iris$Species, mean)
head(iris)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
?apply
apply(iris[, 1:4], mean)
library(mtcars)
library(datasets)
data("mtcars")
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
tapply(mtcars$mpg, mtcars$cyl, mean)
dim(mtcars)
colnames(mtcars)
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
sample <- tapply(mtcars$hp, mtcars$cyl, mean)
sample
sample(1)
sample(2)
sample
class(sample)
sample[1]
sample[3] - sample[1]
debug(ls)
ls
ls
?ls
swirl()
library(swirl)
swirl()
library(iris)
library(datasets)
data("iris")
?lapply
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors,mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flag$animate)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
library(datasets)
data(iris)
head(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
apply(iris, 1, mean)
colMeans(iris)
apply(iris[, 1:4], 1, mean)
rowMeans(iris[, 1:4])
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
sapply(mtcars, cyl, mean)
head(mtcars)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
apply(mtcars, 2, mean)
with(mtcars, tapply(mpg, cyl, mean))
mean(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
209.21429 - 82.63636
ls
debug(ls)
ls
x <- c(rnorm(10), runif(10))
install.packages('RMySQL')
install.packages("arules")
library("arules", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
dataset = longley
linear_model = lm(formula = Employed ~ GNP, data = dataset)
# Visualising the residual values in the graph to identify the outliers
qqnorm(resid(linear_model))
plot(dataset$GNP, dataset$Employed)
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed')
abline(lm(Employed ~ GNP))
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red')
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red', pch = 21)
abline(lm(Employed ~ GNP, data = dataset))
plot(dataset$GNP, dataset$Employed, main = 'Simple Linear', xlab = 'GNP', ylab = 'Employed', col = 'red', pch = 16)
abline(lm(Employed ~ GNP, data = dataset))
View(dataset)
dataset = dataset[, c(2,7)]
View(dataset)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 1) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 2) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 3) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point(shape = 4) +
geom_smooth(method = lm)
ggplot(data = dataset, aes(x =  dataset$GNP, y = dataset$Employed)) +
geom_point() +
geom_smooth(method = lm)
load("/Users/ravikiran/Desktop/R/Air Quality UCI/airquality.RData")
a = c(2,1,2,3,5,6,7,8,2)
sum(a[a == 2])
dataset = mtcars
# Creating a regression model
regressor = lm(mpg~cyl+wt+am+gear+carb, data = dataset)
summary(regressor)$coefficients
summary(regressor)$estimate
summary(regressor)$Estimate
summary(regressor)coefficients
summary(regressor)$coefficients
library("QuantPsyc", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
lm.beta(regressor)
summary(regressor)$coefficients
install.packages("sirt")
setwd("~/Desktop/Imarticus/Academics/class practice/R")
library("mlbench", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Practising the Support Vector Machine Algorithm
dataset = data("BreastCancer")
head(dataset)
# Practising the Support Vector Machine Algorithm
data("BreastCancer")
dataset = BreastCancer
str(dataset)
# Removing the rows that have NA values
dataset = na.omit(dataset)
is.na(dataset)
sum(is.na(dataset))
str(dataset)
View(dataset)
dataset = dataset[-1]
# Convert the factor levels benign and malignant to 0 and 1
dataset$Class = as.factor(dataset$Class, levels = c(1, 0))
# Convert the factor levels benign and malignant to 0 and 1
dataset$Class = as.factor(dataset$Class, c(1, 0))
# Convert the factor levels benign and malignant to 0 and 1
dataset$Class = factor(dataset$Class, levels = c(1, 0))
str(dataset)
dataset = BreastCancer
dataset = na.omit(dataset)
dataset = dataset[-1]
str(dataset)
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Splitting the dataset to train and test set
split = sample.split(dataset$Class, SplitRatio = 0.7)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.7)
train_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Fitting the SVM model from the e1071 package to the training set
classifier = svm(formula = Class ~ ., data = train_set, cost = 4, gamma = 0.5, probability = TRUE)
# Fitting the SVM model from the e1071 package to the training set
classifier = svm(formula = Class ~ ., data = train_set, cost = 4, gamma = 0.5, kernel = 'linear', probability = TRUE)
# Fitting the SVM model from the e1071 package to the training set
classifier = svm(formula = Class ~ ., data = train_set, cost = 4, gamma = 0.5, probability = TRUE)
summary(classifier)
coefficients(classifier)
View(test_set)
test_pred = predict(classifier, type = 'prob', newdata = test_set[-10], probability = TRUE)
test_pred
class(test_pred)
test_pred_df = as.data.frame(test_pred)
View(test_pred_df)
rm(test_pred_df)
tune_classifier = tune(svm, Class ~ ., data = train_set, ranges = list(gamma = 1.5 ^ (-1:1), cost = 1.5 ^ (2:4)))
View(tune_classifier)
1.5 ^ -1
1.5 ^ 2
classifier_best = svm(formula = Class ~ ., data = train_set, cost = 1.5 ^ 2, gamma = 1.5 ^ -1, probability = TRUE)
train_pred = fitted(classifier_best)
test_pred = predict(classifier_best, type = 'prob', newdata = test_set[-10], probability = TRUE)
test_pred_set = cbind(test_set, test_pred)
View(test_pred_set)
library("ROCR", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Calculating the training set ROCR performance with the help of ROCR package
ROCRpred = prediction(train_pred, train_set$Class)
as.numeric(train_set$Class)
test_pred = predict(classifier_best, type = 'prob', newdata = test_set, probability = TRUE)
test_pred_set = cbind(test_set, test_pred)
# Calculating the training set ROCR performance with the help of ROCR package
ROCRpred = prediction(train_pred, train_set$Class)
# Calculating the training set ROCR performance with the help of ROCR package
ROCRpred = prediction(train_pred, as.numeric(train_set$Class))
cm_train = table(train_set$Class, train_pred)
cm_train = as.data.frame(table(train_set$Class, train_pred))
View(cm_train)
cm_train = table(train_set$Class, train_pred)
cm_train
class(cm_train)
cm_test = table(test_set$Class, test_pred)
cm_test
cm_test_df = as.data.frame(cm_test)
View(cm_test_df)
cm_train_df = as.data.frame(cm_train)
accuracy_cm = function(confusionmatrix){
accuracy = (confusionmatrix[1,1] + confusionmatrix[2,2]) / (sum(confusionmatrix))
}
# Calculating the accuracy for the test set confusion matrix
accuracy_cm(cm_test)
cm_test[1,1]
cm_test
# Calculating the accuracy for the test set confusion matrix
accuracy_cm_test = accuracy_cm(cm_test)
accuracy_cm_train = accuracy_cm(cm_train)
getwd()
